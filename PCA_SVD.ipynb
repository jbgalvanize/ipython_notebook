{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Principal Component Analysis (PCA) \n",
    "##AND Singular Value Decomposition (SVD)\n",
    "\n",
    "Before we look at the math, which is a bit tedious, the first thing to note is that these techniques are used for unsupervised problems.  Occasionally, we will use the techniques to create a new feature space in linear or logistic regression in the case that our original feature space is very large; however, we then lose the interpretability of our usually very easy to interpret linear models.  These techniques have also been used to do survey analysis, analyze for recommendation systems, and perform a number of other analyses to difficult statistical problems including image facial recognition and natural language processing. \n",
    "\n",
    "In a technique known as PCR (Principal Component Regression), PCA is designed to create a new set of predictors that are a linear combination of the original predictors.  Nicely enough, PCA assures that our new features (or columns) are linearly independent (or orthogonal) to one another - one of our assumputions in multiple linear regression was exactly this - no multicollinearity. \n",
    "\n",
    "It is important to have a basic idea about the math that is considered for PCA/SVD, so that we know a little bit about the results that occur and how we can use them to understand our data.  If you have a square matrix, then it follows that the eignevalues and eignevectors of the matrix A can be found for all non-zero, eigenvalue solutions for $\\lambda$ as:\n",
    "\n",
    "$$Av = \\lambda v$$\n",
    "\n",
    "where A is our matrix of original data (or our covariance matrix for some set of problems - [\"By finding the eigenvalues and eigenvectors of the covariance matrix, we find that the eigenvectors with the largest eigenvalues correspond to the dimensions that have the strongest correlation in the dataset\"](http://www.cse.psu.edu/~rtc12/CSE586Spring2010/lectures/pcaLectureShort_6pp.pdf)), $\\lambda$ is our eigenvalue, and v is our eigenvector.  For any $\\lambda$, we have a corresponding v that meets the above criteria.  Our vector, v, is known as an eigenvector, and our $\\lambda$ value is known as the corresponding eigenvalue.  However, if our matrix is not square, then we must use singular value decomposition (SVD) to find our eigenvalues and corresponding eigenvectors.  When we are not finding the eigenvalues and eigenvectors of variance-covariance matrix in data science, our matrix for which we would like to find the eigenvalues and eigenvectors is *not* square. \n",
    "\n",
    "On a technical note, eigenvalues and eigenvectors for our non-square matrix do not exist. SVD allows us to find the corollary to eigenvalues and eigenvectors for our non-square matrix, which finds an optimization for a square matrix that will lead to the components with maximum variability to be explained in our original matrix, as explained in the first comment [Here](http://math.stackexchange.com/questions/583938/do-non-square-matrices-have-eigenvalues). Instead of finding eigenvalues and eigenvectors directly, we find the singular values and singular vectors of our original matrix.\n",
    "\n",
    "I will talk through a little bit of the math of SVD before diving into an example and interpretting results.  Using SVD involves decomposing our original $X_{n x p}$ matrix into the following components:\n",
    "\n",
    "$$X_{n x p} = U_{n x n} \\Sigma_{n x p} V'_{p x p}$$\n",
    "\n",
    "\n",
    "$$X = U \\Sigma V'$$\n",
    "\n",
    "such that $\\Sigma$ is a non-negative diagonal matrix with the square root of our eigenvalues as those diagonal elements placed in descending order.  [Here](http://stats.stackexchange.com/questions/134282/relationship-between-svd-and-pca-how-to-use-svd-to-perform-pca) is a link discussing the relationship between PCA and SVD.  \n",
    "\n",
    "The principal components provided by software using SVD can be found as the eigenvectors of $X'X$, which are also the columns of $U$.  Alternatively, the eigenvectors of $XX'$ can be found as the columns of $V$, as described [here](http://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm).  Note, we will want to at least perform centering of our $X$ matrix before calculating the above.  However, it is common to perform a complete normalization of our $X$ matrix.\n",
    "\n",
    "One thing to point out is the similarity between the PCA algorithm and the SVD algorithm, as these prove to be essentially the same task, where SVD is finding all combinations of eigenvalue-eigenvector pairs when A is non-symmetric.  Notice, since $\\lambda$ is a scalar in the following:\n",
    "\n",
    "$$A v = \\lambda v$$\n",
    "\n",
    "I can move it to either side of v with no change to the right side of the equation.  Consider a matrix of $\\sqrt{\\lambda}$ values on the diagonals, and 0's on the off-diagonals for our matrix $\\Sigma$.  We then are looking to decompose A, such that $A = V \\Sigma V'$.  In PCA, the solution to this equation can be found explicitly using \n",
    "\n",
    "$$det(A - I\\lambda) = 0$$\n",
    "\n",
    "to give a combination of the rows of $V$ multiplied by the columns of $\\Sigma$ multiplied by the columns of $V'$ will provide our original matrix A.  Here $V$ is our orthogonal matrix of linear combinations of the original matrix $A$, and $\\Sigma$ holds on the diagonal the square root of our eigenvalues.  In SVD, we have a similar situation, but since $A$ is non-symmetric, we are attempting to find two orthogonal matrices $U$ and $V$ ($U$ is row orthogonal, and $V$ is column orthogonal) that will provide our non-square original matrix $X$.  There is a two part iterative method for finding the converging values of each matrix, which can be found: [Here](https://en.wikipedia.org/wiki/Singular_value_decomposition).  \n",
    "\n",
    "\n",
    "SVD is used across multiple applications.  The lecture notes discuss this method as used in recommendation systems.  However, it can also be used for a range of activities.  I have personally used it for survey analysis.  I will show an example of how to use it to subset your original feature space.  Needless to say - it is a useful method across multiple disciplines.  \n",
    "\n",
    "\n",
    "##Interpretation of the Results\n",
    "\n",
    "The most important part of PCA or SVD is to understand how we can use the results.  The main interpretations to understand are:\n",
    "\n",
    "* Squaring the diagonal elements of $\\Sigma$ gives us the eigenvalues.  Eigenvalues are useful, as they provide to us the amount of variability in the original space of $X$ that can be explained by the linear combination of our matrix with the eigenvector associated with that particular eigenvalue.  \n",
    "\n",
    "\n",
    "* As provided above, each eigenvalue has an associated eigenvector.  The eigenvector gives us a linear combination of the original columns that can be used to create a new column.  The amount of variability in the original columns that can be captured by simply using this new column is the value provided by the eigenvector (this is basically the same as the above point, but stresses the importance of eigenvalues and eigenvectors).  \n",
    "\n",
    "\n",
    "* The individual components (elements) of an eigenvector are often called the 'weights'.  They provide to us the importance of each original column in creating the new column as discussed in point two.  \n",
    "\n",
    "Examples extending from class activities:\n",
    "\n",
    "* Consider we want to reduce the number of predictor variables we use in a linear regression model, but still account for 90% of the variability of our original feature space (with the idea being that the features that are most variable will help us best account for the variability in the response).  We can do PCA and find out a set of new predictor variables that will account for this amount of variability that are also linearly independent columns.  Unfortunately, we lose interpretability by centering our data, as well as creating linear combinations of our original features.  \n",
    "\n",
    "\n",
    "* Consider we want to reduce the number of questions on a survey, but keep the questions that are best at capturing the largest variability in customer responses.  We also want to know which questions seem to be most associated with one another.  In survey analysis, each component is generally indicative of a set of questions that are aimed at a particular topic.  The weights of each column tell us the importance of each question to that particular topic.  The eigenvalue provides to us the amount of variability in all responses across all questions that can be explained by that particular component of the survey.  This can help us reduce the total number of questions on our survey while still capturing all the necessary information from our consumers.\n",
    "\n",
    "\n",
    "##PCA and SVD using Python\n",
    "\n",
    "A basic introduction to principal component analysis using Python.  Here, we will simply look at the main output you obtain from running a PCA and how you should interpret these results.  A very strong example of all of the steps incorporated with doing PCA can be found [Here](http://sebastianraschka.com/Articles/2014_pca_step_by_step.html).  I will be showing how to use the 'built in' functions to get results, and then I will focus on an interpretation of these results. \n",
    "\n",
    "First, let's get started with our libraries and using some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.stats.outliers_influence as sm_o\n",
    "import seaborn as sb \n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston = pd.DataFrame(datasets.load_boston()['data'])\n",
    "boston.columns = datasets.load_boston()['feature_names']\n",
    "boston_target = datasets.load_boston()['target']\n",
    "#datasets.load_boston()['DESCR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM  ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        B  LSTAT  \n",
       "0  396.90   4.98  \n",
       "1  396.90   9.14  \n",
       "2  392.83   4.03  \n",
       "3  394.63   2.94  \n",
       "4  396.90   5.33  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to normalize our X matrix.  Note, without normalizing certain features will outweigh others simply because of the units.  We want to know which features have the maximum variability after accounting for the units, as we hope that the features with the most variability will be able to attribute for the variability in our response in PCR. In unsupervised approaches we want new features that can be associated with the most variability in the original feature space because it will allow us to reduce to the fewest number of new features that can still help us understand as much as possible about the original features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bost_norm = (boston - boston.mean()) / (boston.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the following code to perform PCA on our dataframe, as well as find the percent of variability explained by each component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = decomposition.PCA()\n",
    "pca.fit(bost_norm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can find the amount of variability explained by any individual, new component (a linear combination of our original components) as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eigenvalues = pca.explained_variance_/sum(pca.explained_variance_);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear combination of our original components needed to create the new component can be found within the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "components = pca.components_;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.47097344,  0.58113216,  0.67660624,  0.74259077,  0.80678817,\n",
       "        0.85753052,  0.8989934 ,  0.9294968 ,  0.95083795,  0.96778101,\n",
       "        0.98210131,  0.99511419,  1.        ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEZCAYAAAB4hzlwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a8a7150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(eigenvalues);\n",
    "plt.title('Skree Plot');\n",
    "plt.xlabel('Component');\n",
    "plt.ylabel('Eigenvalue');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
